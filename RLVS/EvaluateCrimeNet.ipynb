{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93117052aab7154b",
   "metadata": {},
   "source": [
    "# Evaluation CrimeNet with RLVS test videos\n",
    "\n",
    "## Load test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T17:26:23.916208300Z",
     "start_time": "2024-03-15T17:26:23.791531700Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "path_videos_nv = '/home/user/work/data/RLVS/NonViolence/'\n",
    "path_videos_v = '/home/user/work/data/RLVS/Violence/'\n",
    "\n",
    "videos_v = os.listdir(path_videos_v)\n",
    "videos_nv = os.listdir(path_videos_nv)\n",
    "\n",
    "label_videos_v = [1 for i in videos_v]\n",
    "label_videos_nv = [0 for j in videos_nv]\n",
    "\n",
    "videos = videos_v + videos_nv\n",
    "label_videos = label_videos_v + label_videos_nv\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bc25f12c7de84",
   "metadata": {},
   "source": [
    "## Functions to read videos and optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3568ecddd0d355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T17:26:23.955170800Z",
     "start_time": "2024-03-15T17:26:23.921209600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define la función de lectura de vídeo\n",
    "def read_video_optical_flow(vid, width, height, resize=False):\n",
    "    video_frames_optical_flow = list()\n",
    "    i = 0\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    ret1, frame1 = cap.read()\n",
    "    if resize:\n",
    "        frame1 = cv2.resize(frame1, (width, height))\n",
    "    prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = np.zeros_like(frame1)\n",
    "    hsv[..., 1] = 255\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret2, frame2 = cap.read()\n",
    "        if ret2:\n",
    "            if resize:\n",
    "                frame2 = cv2.resize(frame2, (width, height))\n",
    "            next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "            flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "            hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "            hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "            bgr = np.reshape(bgr, (width, height, channels))\n",
    "            video_frames_optical_flow.append(bgr)\n",
    "        else:\n",
    "            break\n",
    "        i += 1\n",
    "        prvs = next\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return video_frames_optical_flow\n",
    "\n",
    "# Define la función de lectura de vídeo\n",
    "def read_video(vid, width, height, resize=False):\n",
    "    video_frames = list()\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            if resize:\n",
    "                frame = cv2.resize(frame, (width, height))\n",
    "                frame = np.reshape(frame, (width, height, channels))\n",
    "            video_frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return video_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e9f48341b7bc5",
   "metadata": {},
   "source": [
    "## Load pre-trained CrimeNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f96291e333e7f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T17:26:38.712927700Z",
     "start_time": "2024-03-15T17:26:23.943170100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:57:40.667516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-30 11:57:40.761161: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-30 11:57:41.133997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-03-30 11:57:41.134043: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2024-03-30 11:57:41.134049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-03-30 11:57:41.970093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:41.976126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:41.976336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:41.976772: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-30 11:57:41.977301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:41.977441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:41.977559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:42.302685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:42.302846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:42.302962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-30 11:57:42.303053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22062 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:07:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f8bf837e730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ViT import *\n",
    "import neural_structured_learning as nsl\n",
    "\n",
    "vit_model = create_vit_classifier()\n",
    "\n",
    "\n",
    "adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2,\n",
    "                                             adv_step_size=0.05,\n",
    "                                             adv_grad_norm='infinity')\n",
    "\n",
    "adv_model = nsl.keras.AdversarialRegularization(vit_model,\n",
    "                                                label_keys=['label'],\n",
    "                                                adv_config=adv_config)\n",
    "\n",
    "adv_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=[# tf.keras.metrics.TruePositives(name='tp'),\n",
    "                           # tf.keras.metrics.FalsePositives(name='fp'),\n",
    "                           # tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "                           # tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "                           # tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                           tf.keras.metrics.AUC(curve=\"ROC\"),\n",
    "                           tf.keras.metrics.AUC(curve=\"PR\")])\n",
    "\n",
    "\n",
    "adv_model.load_weights('/home/user/work/shared-CrimeNet/RLVS/Results/logs/checkpoint/20240329-143918')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1fef23601dfdff",
   "metadata": {},
   "source": [
    "## Load and shuffle test dataset videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e29036da002ce56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T17:40:10.823935900Z",
     "start_time": "2024-03-15T17:26:38.751843500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_368.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_817.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_485.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_630.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_365.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_587.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_549.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_641.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_334.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_974.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_30.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_570.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_217.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_471.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_119.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_847.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_830.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_807.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_242.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_983.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_500.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_357.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_55.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_14.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_204.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_542.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_894.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_505.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_866.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_854.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_829.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_397.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_16.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_70.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_714.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_858.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_839.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_140.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_967.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_314.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_356.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_319.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_301.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_79.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_579.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_183.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_704.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_126.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_898.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_469.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_434.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_815.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_976.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_937.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_318.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_477.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_531.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_482.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_984.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_994.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_472.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_271.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_662.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_408.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_879.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_23.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_740.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_61.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_347.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_92.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_814.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_112.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_909.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_543.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_44.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_292.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_616.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_936.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_677.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_446.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_376.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_310.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_61.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_428.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_877.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_601.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_331.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_103.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_455.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_84.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_831.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_667.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_529.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_535.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_445.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_586.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_168.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_728.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_12.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_75.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_17.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_473.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_6.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_449.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_852.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_196.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_918.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_53.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_13.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_572.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_781.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_951.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_653.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_725.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_859.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_43.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_840.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_935.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_640.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_323.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_388.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_266.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_795.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_649.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_512.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_746.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_262.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_127.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_817.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_374.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_362.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_202.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_390.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_933.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_148.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_853.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_412.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_905.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_827.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_553.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_345.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_150.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_691.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_430.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_95.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_288.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_621.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_27.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_769.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_26.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_992.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_332.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_451.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_732.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_800.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_850.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_556.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_665.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_303.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_794.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_398.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_707.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_656.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_428.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_754.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_179.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_969.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_513.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_382.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_767.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_224.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_563.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_458.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_147.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_145.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_716.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_760.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_895.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_892.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_80.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_538.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_224.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_354.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_889.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_162.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_222.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_289.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_118.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_508.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_5.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_245.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_104.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_552.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_241.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_157.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_648.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_718.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/NV_903.avi\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_386.mp4\n",
      "Loading Test: /home/user/work/data/RLVS/NonViolence/V_20.mp4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_valid_test = []\n",
    "y_valid_test = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_valid_index in split.split(videos, label_videos):\n",
    "    for ti in train_index:\n",
    "        X_train.append(videos[ti])\n",
    "        y_train.append(label_videos[ti])\n",
    "\n",
    "    for tsi in test_valid_index:\n",
    "        X_valid_test.append(videos[tsi])\n",
    "        y_valid_test.append(label_videos[tsi])\n",
    "\n",
    "split2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n",
    "for test_index, valid_index in split2.split(X_valid_test, y_valid_test):\n",
    "    for tssi in test_index:\n",
    "        X_test.append(X_valid_test[tssi])\n",
    "        y_test.append(y_valid_test[tssi])\n",
    "\n",
    "    for tvi in valid_index:\n",
    "        X_valid.append(X_valid_test[tvi])\n",
    "        y_valid.append(y_valid_test[tvi])\n",
    "        \n",
    "test_total_op = []\n",
    "test_total_rgb = []\n",
    "for i in range(len(X_test)):\n",
    "    if 'NV' in X_test[i]:\n",
    "        print('Loading Test: ' + path_videos_nv + X_test[i])\n",
    "        video_frames_op = read_video_optical_flow(path_videos_nv + X_test[i], 20, 20, resize=True)\n",
    "        video_frames_rgb = read_video(path_videos_nv + X_test[i], 20, 20, resize=True)\n",
    "    else:\n",
    "        print('Loading Test: ' + path_videos_nv + X_test[i])\n",
    "        video_frames_op = read_video_optical_flow(path_videos_v + X_test[i], 20, 20, resize=True)\n",
    "        video_frames_rgb = read_video(path_videos_v + X_test[i], 20, 20, resize=True)\n",
    "    for j in range(len(video_frames_op)):\n",
    "        fr_op = video_frames_op[j]\n",
    "        fr_rgb = video_frames_rgb[j]\n",
    "        if 'NV' in X_test:\n",
    "            test_total_op.append((fr_op, 0))\n",
    "            test_total_rgb.append((fr_rgb, 0))\n",
    "        else:\n",
    "            test_total_op.append((fr_op, 1))\n",
    "            test_total_rgb.append((fr_rgb, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94431996017fc931",
   "metadata": {},
   "source": [
    "## Function to generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4304214890a37e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T17:26:38.767036400Z",
     "start_time": "2024-03-15T17:26:38.716928700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "def generatorTestData(batch_size_test=16):\n",
    "    while True:\n",
    "        for count in range(int(len(test_total_op) / batch_size_test)):\n",
    "            batch_start = batch_size_test * count\n",
    "            batch_stop = batch_size_test + (batch_size_test * count)\n",
    "            lx_op = []\n",
    "            lx_rgb = []\n",
    "            ly = []\n",
    "\n",
    "            for i in range(batch_start, batch_stop):\n",
    "                frame_op = cv2.resize(test_total_op[i][0], (width, height))\n",
    "                frame_op = (frame_op.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "                frame_rgb = cv2.resize(test_total_rgb[i][0], (width, height))\n",
    "                frame_rgb = (frame_rgb.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "                label = test_total_op[i][1]\n",
    "\n",
    "                lx_op.append(frame_op)\n",
    "                lx_rgb.append(frame_rgb)\n",
    "                ly.append(label)\n",
    "\n",
    "            x_op = np.array(lx_op).astype('float32')\n",
    "            x_rgb = np.array(lx_rgb).astype('float32')\n",
    "\n",
    "            y = np.array(ly).astype('float32')\n",
    "            y = tf.keras.utils.to_categorical(y, num_classes=num_classes, dtype='float32')\n",
    "\n",
    "            x_op = tf.convert_to_tensor(x_op)\n",
    "            x_rgb = tf.convert_to_tensor(x_rgb)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "\n",
    "            yield {'feature_1': x_op, 'feature_2': x_rgb, 'label': y}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ad69acf23c57c",
   "metadata": {},
   "source": [
    "## Evaluation test dataset videos with CrimeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c795a460bdbbdebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T18:42:23.785615800Z",
     "start_time": "2024-03-15T17:40:10.826938900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:58:06.631548: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "WARNING:absl:Cannot perturb features dict_keys(['label'])\n",
      "WARNING:absl:Cannot perturb features dict_keys(['label'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31830/31830 [==============================] - 1582s 49ms/step - loss: 4.8085e-07 - auc: 1.0000 - auc_1: 1.0000 - categorical_crossentropy: 0.0000e+00 - scaled_adversarial_loss: 4.8085e-07\n",
      "Inference time: 0.04974933064586892\n"
     ]
    }
   ],
   "source": [
    "start_time_test = time.time()\n",
    "adv_model.evaluate(generatorTestData(batch_size_test=1),\n",
    "                   steps=int(len(test_total_op) / 1))\n",
    "print('Inference time: ' + str((time.time() - start_time_test) / len(test_total_op)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
